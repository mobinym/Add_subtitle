{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy as mp\n",
    "import whisper\n",
    "import deep_translator as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio(video_path, output_audio):\n",
    " \n",
    "    video = mp.VideoFileClip(video_path)\n",
    "    \n",
    "\n",
    "    video.audio.write_audiofile(output_audio)\n",
    "    \n",
    "\n",
    "\n",
    "    video.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [720, 1280], 'bitrate': 1091, 'fps': 30.0, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'AVC Coding'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 76, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 63.2, 'bitrate': 1172, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [720, 1280], 'video_bitrate': 1091, 'video_fps': 30.0, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 76, 'video_duration': 63.2, 'video_n_frames': 1896}\n",
      "/opt/anaconda3/lib/python3.12/site-packages/imageio_ffmpeg/binaries/ffmpeg-macos-aarch64-v7.1 -i short-clip.mp4 -loglevel error -f image2pipe -vf scale=720:1280 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "MoviePy - Writing audio in final.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "video_path = \"short-clip.mp4\"\n",
    "output_audio = \"final.mp3\" \n",
    "\n",
    "extract_audio(video_path, output_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In other's eyes, this is a box of milk, but in his eyes it's the key to escaping prison. He carefully opens the milk carton, and inside there's a thin layer of wax film. He peels off the film and cleans it. When the guards are out, he sticks it on the combination lock. Next, when the prison guard inputs the password, his fingerprints will be left on four of the keys. Then he carefully peels off the film. By observing the fingerprint marks, he can identify the positions of the four keys, and calculate 24 possible combinations. Next comes the password testing, but the problem is how to touch the lock. He rolls toilet paper into small balls, fills them with toothpaste, and makes more small balls. Then he wraps these balls in paper, molds them tight, and eventually makes a big sticky ball. When the guard unlocks his handcuffs, he quietly pushes the sticky ball into the small windows lock hole. That way, even if the guard locks the small window, he can easily push it open. By reaching his hand through the small window, he can try up to 24 times. You'll crack the code in no time.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def speech_to_text(audio_file, language=\"en\"):\n",
    "    \"\"\"\n",
    "    پردازش فایل صوتی و تبدیل آن به متن\n",
    "    :param audio_file: مسیر فایل صوتی\n",
    "    :param language: زبانی که باید متن استخراج شود ('fa' برای فارسی، 'en' برای انگلیسی، 'auto' برای شناسایی خودکار)\n",
    "    :return: متن استخراج‌شده\n",
    "    \"\"\"\n",
    "    model = whisper.load_model(\"tiny\")  \n",
    "\n",
    "    if language == \"en\":\n",
    "        result = model.transcribe(audio_file) \n",
    "    else:\n",
    "        result = model.transcribe(audio_file, language=language)\n",
    "\n",
    "    return result[\"text\"]\n",
    "\n",
    "audio_path = \"final.mp3\"  \n",
    "detected_text = speech_to_text(audio_path, language=\"en\") \n",
    "print(detected_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "از نظر دیگران ، این یک جعبه شیر است ، اما از نظر او کلید فرار از زندان است. او با دقت کارتن شیر را باز می کند و در داخل یک لایه نازک از فیلم موم وجود دارد. او فیلم را بیرون می کشد و آن را تمیز می کند. وقتی نگهبانان خارج هستند ، او آن را روی قفل ترکیبی می چسباند. بعد ، هنگامی که نگهبان زندان رمز ورود را وارد می کند ، اثر انگشت وی روی چهار کلید باقی می ماند. سپس او با دقت فیلم را از بین می برد. او با مشاهده علائم اثر انگشت می تواند موقعیت های چهار کلید را شناسایی کند و 24 ترکیب ممکن را محاسبه کند. تست رمز عبور بعدی انجام می شود ، اما مشکل این است که چگونه قفل را لمس کنید. او کاغذ توالت را درون توپ های کوچک می چرخاند ، آنها را با خمیر دندان پر می کند و توپ های کوچک تری می سازد. سپس او این توپ ها را در کاغذ می پیچد ، آنها را محکم می کند و در نهایت یک توپ چسبنده بزرگ می کند. هنگامی که نگهبان دستبندهای خود را باز می کند ، بی سر و صدا توپ چسبنده را به درون قفل قفل پنجره های کوچک سوق می دهد. به این ترتیب ، حتی اگر نگهبان پنجره کوچک را قفل کند ، می تواند به راحتی آن را باز کند. با رسیدن به دست خود از طریق پنجره کوچک ، او می تواند حداکثر 24 بار را امتحان کند. شما در هر زمان کد را ترک نمی کنید.\n"
     ]
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "translated_text = GoogleTranslator(source='en', target='fa').translate(detected_text)\n",
    "\n",
    "print(translated_text) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "def speech_to_text(audio_file, language=\"en\"):\n",
    "    \"\"\"\n",
    "    پردازش فایل صوتی و تبدیل آن به متن\n",
    "    :param audio_file: مسیر فایل صوتی\n",
    "    :param language: زبانی که باید متن استخراج شود ('fa' برای فارسی، 'en' برای انگلیسی، 'auto' برای شناسایی خودکار)\n",
    "    :return: نتیجه شامل متن و زمان‌بندی بخش‌ها\n",
    "    \"\"\"\n",
    "    model = whisper.load_model(\"tiny\")  \n",
    "\n",
    "    if language == \"en\":\n",
    "        result = model.transcribe(audio_file)  \n",
    "    else:\n",
    "        result = model.transcribe(audio_file, language=language)\n",
    "\n",
    "    return result\n",
    "\n",
    "def seconds_to_srt_time(seconds):\n",
    "    \"\"\"\n",
    "    تبدیل زمان به فرمت SRT\n",
    "    :param seconds: زمان به‌صورت اعشاری\n",
    "    :return: زمان به‌صورت رشته‌ای با فرمت SRT\n",
    "    \"\"\"\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    secs = int(seconds % 60)\n",
    "    millis = int((seconds % 1) * 1000)\n",
    "    return f\"{hours:02}:{minutes:02}:{secs:02},{millis:03}\"\n",
    "\n",
    "def generate_srt_from_segments(segments, output_srt_path):\n",
    "    \"\"\"\n",
    "    تولید فایل SRT برای زیرنویس با استفاده از زمان‌بندی دقیق\n",
    "    :param segments: بخش‌های استخراج‌شده شامل زمان و متن\n",
    "    :param output_srt_path: مسیر ذخیره فایل SRT\n",
    "    \"\"\"\n",
    "    with open(output_srt_path, \"w\", encoding=\"utf-8\") as srt_file:\n",
    "        for i, segment in enumerate(segments, start=1):\n",
    "            start_time = seconds_to_srt_time(segment[\"start\"])\n",
    "            end_time = seconds_to_srt_time(segment[\"end\"])\n",
    "            text = segment[\"text\"].strip()\n",
    "            srt_file.write(f\"{i}\\n{start_time} --> {end_time}\\n{text}\\n\\n\")\n",
    "\n",
    "audio_path = \"final.mp3\" \n",
    "result = speech_to_text(audio_path, language=\"en\")\n",
    "\n",
    "translated_text = GoogleTranslator(source='en', target='fa').translate(result[\"text\"])\n",
    "\n",
    "generate_srt_from_segments(result[\"segments\"], \"subtitle.srt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persian save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "import whisper\n",
    "\n",
    "def speech_to_text(audio_file, language=\"en\"):\n",
    "    \"\"\"\n",
    "    پردازش فایل صوتی و تبدیل آن به متن\n",
    "    :param audio_file: مسیر فایل صوتی\n",
    "    :param language: زبانی که باید متن استخراج شود ('fa' برای فارسی، 'en' برای انگلیسی، 'auto' برای شناسایی خودکار)\n",
    "    :return: نتیجه شامل متن و زمان‌بندی بخش‌ها\n",
    "    \"\"\"\n",
    "    model = whisper.load_model(\"tiny\")  \n",
    "\n",
    "    if language == \"en\":\n",
    "        result = model.transcribe(audio_file)  \n",
    "    else:\n",
    "        result = model.transcribe(audio_file, language=language)\n",
    "\n",
    "    return result\n",
    "\n",
    "def seconds_to_srt_time(seconds):\n",
    "    \"\"\"\n",
    "    تبدیل زمان به فرمت SRT\n",
    "    :param seconds: زمان به‌صورت اعشاری\n",
    "    :return: زمان به‌صورت رشته‌ای با فرمت SRT\n",
    "    \"\"\"\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    secs = int(seconds % 60)\n",
    "    millis = int((seconds % 1) * 1000)\n",
    "    return f\"{hours:02}:{minutes:02}:{secs:02},{millis:03}\"\n",
    "\n",
    "def generate_srt_from_segments(segments, output_srt_path, translate_to_farsi=False):\n",
    "    \"\"\"\n",
    "    تولید فایل SRT برای زیرنویس با استفاده از زمان‌بندی دقیق\n",
    "    :param segments: بخش‌های استخراج‌شده شامل زمان و متن\n",
    "    :param output_srt_path: مسیر ذخیره فایل SRT\n",
    "    :param translate_to_farsi: اگر True باشد، متن به فارسی ترجمه می‌شود\n",
    "    \"\"\"\n",
    "    with open(output_srt_path, \"w\", encoding=\"utf-8\") as srt_file:\n",
    "        for i, segment in enumerate(segments, start=1):\n",
    "            start_time = seconds_to_srt_time(segment[\"start\"])\n",
    "            end_time = seconds_to_srt_time(segment[\"end\"])\n",
    "            text = segment[\"text\"].strip()\n",
    "            \n",
    "            if translate_to_farsi:\n",
    "                # ترجمه به فارسی\n",
    "                translated_text = GoogleTranslator(source='en', target='fa').translate(text)\n",
    "                text = translated_text\n",
    "            \n",
    "            srt_file.write(f\"{i}\\n{start_time} --> {end_time}\\n{text}\\n\\n\")\n",
    "\n",
    "audio_path = \"final.mp3\"  \n",
    "result = speech_to_text(audio_path, language=\"en\")\n",
    "\n",
    "generate_srt_from_segments(result[\"segments\"], \"subtitle.srt\", translate_to_farsi=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "english sub in video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "\n",
    "def read_srt(srt_file):\n",
    "    \"\"\"\n",
    "    خواندن فایل SRT و استخراج زیرنویس‌ها به‌همراه زمان‌ها\n",
    "    :param srt_file: مسیر فایل SRT\n",
    "    :return: لیست دیکشنری‌های شامل زمان شروع، پایان و متن هر زیرنویس\n",
    "    \"\"\"\n",
    "    subtitles = []\n",
    "    with open(srt_file, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    index = 0\n",
    "    while index < len(lines):\n",
    "        if lines[index].strip().isdigit():\n",
    "            start, end = lines[index + 1].strip().split(' --> ')\n",
    "            text = lines[index + 2].strip()\n",
    "            start = convert_time_to_seconds(start)\n",
    "            end = convert_time_to_seconds(end)\n",
    "            subtitles.append({'start': start, 'end': end, 'text': text})\n",
    "        \n",
    "        index += 4  \n",
    "    \n",
    "    return subtitles\n",
    "\n",
    "def convert_time_to_seconds(time_str):\n",
    "    \"\"\"\n",
    "    تبدیل زمان SRT به ثانیه\n",
    "    :param time_str: زمان به فرمت SRT (مثال: 00:01:23,456)\n",
    "    :return: زمان به ثانیه\n",
    "    \"\"\"\n",
    "    h, m, s = time_str.replace(',', '.').split(':')\n",
    "    return int(h) * 3600 + int(m) * 60 + float(s)\n",
    "\n",
    "def break_long_lines(text, max_chars=30):\n",
    "    \"\"\"\n",
    "    شکستن خطوط بلند به خطوط کوتاه‌تر\n",
    "    :param text: متن اصلی\n",
    "    :param max_chars: حداکثر تعداد کاراکتر در هر خط\n",
    "    :return: متن شکسته‌شده به چند خط\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    lines = []\n",
    "    current_line = \"\"\n",
    "    for word in words:\n",
    "        if len(current_line) + len(word) + 1 <= max_chars:\n",
    "            current_line += \" \" + word\n",
    "        else:\n",
    "            lines.append(current_line.strip())\n",
    "            current_line = word\n",
    "    lines.append(current_line.strip())\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def add_subtitles_with_opencv(video_path, srt_file, output_path, font_path='arial.ttf', font_size=24):\n",
    "    \"\"\"\n",
    "    اضافه کردن زیرنویس به ویدیو با OpenCV\n",
    "    :param video_path: مسیر ویدیوی اصلی\n",
    "    :param srt_file: مسیر فایل SRT\n",
    "    :param output_path: مسیر ویدیوی خروجی\n",
    "    :param font_path: مسیر فونت TrueType\n",
    "    :param font_size: اندازه فونت زیرنویس\n",
    "    \"\"\"\n",
    "    subtitles = read_srt(srt_file)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "        \n",
    "        for subtitle in subtitles:\n",
    "            if subtitle['start'] <= current_time <= subtitle['end']:\n",
    "                text = break_long_lines(subtitle['text'])\n",
    "                \n",
    "                frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "                draw = ImageDraw.Draw(frame_pil)\n",
    "                \n",
    "                bbox = draw.textbbox((0, 0), text, font=font)\n",
    "                text_width = bbox[2] - bbox[0]\n",
    "                text_height = bbox[3] - bbox[1]\n",
    "                \n",
    "                x = (width - text_width) // 2\n",
    "                y = height - text_height - 30\n",
    "                \n",
    "                box_padding = 10\n",
    "                box_coords = [x - box_padding, y - box_padding, \n",
    "                              x + text_width + box_padding, y + text_height + box_padding]\n",
    "                draw.rectangle(box_coords, fill=(0, 0, 0, 150))\n",
    "                \n",
    "                draw.text((x, y), text, font=font, fill=(255, 255, 255))\n",
    "                \n",
    "                frame = cv2.cvtColor(np.array(frame_pil), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        out.write(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "add_subtitles_with_opencv(\"short-clip.mp4\", \"subtitle.srt\", \"output_video.mp4\", font_path='/Library/Fonts/Arial.ttf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "persian sub in video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "persian sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "\n",
    "def read_srt(srt_file):\n",
    "    \"\"\"\n",
    "    خواندن فایل SRT و استخراج زیرنویس‌ها به‌همراه زمان‌ها\n",
    "    :param srt_file: مسیر فایل SRT\n",
    "    :return: لیست دیکشنری‌های شامل زمان شروع، پایان و متن هر زیرنویس\n",
    "    \"\"\"\n",
    "    subtitles = []\n",
    "    with open(srt_file, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    index = 0\n",
    "    while index < len(lines):\n",
    "        if lines[index].strip().isdigit():\n",
    "            start, end = lines[index + 1].strip().split(' --> ')\n",
    "            text = lines[index + 2].strip()\n",
    "            start = convert_time_to_seconds(start)\n",
    "            end = convert_time_to_seconds(end)\n",
    "            subtitles.append({'start': start, 'end': end, 'text': text})\n",
    "        \n",
    "        index += 4  \n",
    "    \n",
    "    return subtitles\n",
    "\n",
    "def convert_time_to_seconds(time_str):\n",
    "    \"\"\"\n",
    "    تبدیل زمان SRT به ثانیه\n",
    "    :param time_str: زمان به فرمت SRT (مثال: 00:01:23,456)\n",
    "    :return: زمان به ثانیه\n",
    "    \"\"\"\n",
    "    h, m, s = time_str.replace(',', '.').split(':')\n",
    "    return int(h) * 3600 + int(m) * 60 + float(s)\n",
    "\n",
    "def break_long_lines(text, max_chars=30):\n",
    "    \"\"\"\n",
    "    شکستن خطوط بلند به خطوط کوتاه‌تر\n",
    "    :param text: متن اصلی\n",
    "    :param max_chars: حداکثر تعداد کاراکتر در هر خط\n",
    "    :return: متن شکسته‌شده به چند خط\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    lines = []\n",
    "    current_line = \"\"\n",
    "    for word in words:\n",
    "        if len(current_line) + len(word) + 1 <= max_chars:\n",
    "            current_line += \" \" + word\n",
    "        else:\n",
    "            lines.append(current_line.strip())\n",
    "            current_line = word\n",
    "    lines.append(current_line.strip())\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def add_subtitles_with_opencv(video_path, srt_file, output_path, font_path='arial.ttf', font_size=24):\n",
    "    \"\"\"\n",
    "    اضافه کردن زیرنویس به ویدیو با OpenCV\n",
    "    :param video_path: مسیر ویدیوی اصلی\n",
    "    :param srt_file: مسیر فایل SRT\n",
    "    :param output_path: مسیر ویدیوی خروجی\n",
    "    :param font_path: مسیر فونت TrueType\n",
    "    :param font_size: اندازه فونت زیرنویس\n",
    "    \"\"\"\n",
    "    subtitles = read_srt(srt_file)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "        \n",
    "        for subtitle in subtitles:\n",
    "            if subtitle['start'] <= current_time <= subtitle['end']:\n",
    "                text = break_long_lines(subtitle['text'])\n",
    "                \n",
    "                reshaped_text = arabic_reshaper.reshape(text)  # اصلاح جهت‌گیری\n",
    "                bidi_text = get_display(reshaped_text)  # تبدیل متن به جهت درست\n",
    "                \n",
    "                frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "                draw = ImageDraw.Draw(frame_pil)\n",
    "                \n",
    "                bbox = draw.textbbox((0, 0), bidi_text, font=font)\n",
    "                text_width = bbox[2] - bbox[0]\n",
    "                text_height = bbox[3] - bbox[1]\n",
    "                \n",
    "                x = (width - text_width) // 2\n",
    "                y = height - text_height - 30\n",
    "                \n",
    "                # رسم کادر مشکی نیمه‌شفاف\n",
    "                box_padding = 10\n",
    "                box_coords = [x - box_padding, y - box_padding, \n",
    "                              x + text_width + box_padding, y + text_height + box_padding]\n",
    "                draw.rectangle(box_coords, fill=(0, 0, 0, 150))\n",
    "                \n",
    "                # رسم متن روی کادر\n",
    "                draw.text((x, y), bidi_text, font=font, fill=(255, 255, 255))\n",
    "                \n",
    "                # تبدیل مجدد به BGR برای OpenCV\n",
    "                frame = cv2.cvtColor(np.array(frame_pil), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        out.write(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "add_subtitles_with_opencv(\"short-clip.mp4\", \"subtitle.srt\", \"output_video.mp4\", font_path='/Library/Fonts/Arial.ttf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert voice and video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 16.0.0 (clang-1600.0.26.4)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.100 / 61. 19.100\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'temp_video.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf61.7.100\n",
      "  Duration: 00:01:03.10, start: 0.000000, bitrate: 4834 kb/s\n",
      "  Stream #0:0[0x1](und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 720x1280 [SAR 1:1 DAR 9:16], 4833 kb/s, 30 fps, 30 tbr, 15360 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "[aist#1:0/pcm_s16le @ 0x115604e30] Guessed Channel Layout: stereo\n",
      "Input #1, wav, from 'temp_audio.wav':\n",
      "  Duration: 00:01:03.20, bitrate: 1411 kb/s\n",
      "  Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #1:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp4, to 'final_output.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf61.7.100\n",
      "  Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 720x1280 [SAR 1:1 DAR 9:16], q=2-31, 4833 kb/s, 30 fps, 30 tbr, 15360 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.19.100 aac\n",
      "[out#0/mp4 @ 0x115605110] video:37230KiB audio:1003KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.141752%\n",
      "frame= 1893 fps=0.0 q=-1.0 Lsize=   38287KiB time=00:01:03.10 bitrate=4970.7kbits/s speed= 109x    \n",
      "[aac @ 0x115608450] Qavg: 678.278\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "def add_audio_to_video(video_path, audio_path, output_path):\n",
    "    audio = AudioSegment.from_mp3(audio_path)\n",
    "    audio_frame_rate = audio.frame_rate\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(\"temp_video.mp4\", fourcc, fps, (width, height))\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        out.write(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    audio.export(\"temp_audio.wav\", format=\"wav\")\n",
    "    \n",
    "    os.system(f\"ffmpeg -i temp_video.mp4 -i temp_audio.wav -c:v copy -c:a aac -strict experimental {output_path}\")\n",
    "    \n",
    "    os.remove(\"temp_video.mp4\")\n",
    "    os.remove(\"temp_audio.wav\")\n",
    "\n",
    "add_audio_to_video(\"output_video.mp4\", \"final.mp3\", \"final_output.mp4\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
